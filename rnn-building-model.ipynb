{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53b6dc04",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-20T12:57:20.156842Z",
     "iopub.status.busy": "2024-11-20T12:57:20.156470Z",
     "iopub.status.idle": "2024-11-20T12:57:33.470393Z",
     "shell.execute_reply": "2024-11-20T12:57:33.469440Z"
    },
    "papermill": {
     "duration": 13.322751,
     "end_time": "2024-11-20T12:57:33.472616",
     "exception": false,
     "start_time": "2024-11-20T12:57:20.149865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from IPython.display import clear_output\n",
    "import pickle\n",
    "import librosa\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "#from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, Callback\n",
    "from tensorflow.keras.models import Model, load_model, Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization, GRU, SimpleRNN\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117a4229",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T12:57:33.482605Z",
     "iopub.status.busy": "2024-11-20T12:57:33.482066Z",
     "iopub.status.idle": "2024-11-20T12:57:33.486119Z",
     "shell.execute_reply": "2024-11-20T12:57:33.485439Z"
    },
    "papermill": {
     "duration": 0.010643,
     "end_time": "2024-11-20T12:57:33.487746",
     "exception": false,
     "start_time": "2024-11-20T12:57:33.477103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/kaggle/input/all-people-df/df')\n",
    "\n",
    "# Ścieżka do folderu, w którym znajdują się katalogi z nagraniami osób.\n",
    "file_path = '/kaggle/input/audio-to-train-model/train-clean-100'\n",
    "\n",
    "# Wyciągam wszystkie nazwy podfolderów z powyższej ścieżki (są to ID nagranych osób).\n",
    "subfolders = [f.name for f in os.scandir(file_path) if f.is_dir()]\n",
    "\n",
    "# Sortuję ID nagranych osób (najpierw muszę zamienić ID na liczbę).\n",
    "subfolders = sorted([int(item) for item in subfolders])\n",
    "subfolders = np.array(subfolders)\n",
    "\n",
    "df = df.loc[np.isin(np.array(df['ID']), subfolders)]\n",
    "\n",
    "# Tworzę oddzielne ramki dla kobiet i mężczyzn.\n",
    "df_woman = df[df['SEX'] == ' F '].reset_index(drop=True)\n",
    "df_man = df[df['SEX'] == ' M '].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d258799d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T12:57:33.497097Z",
     "iopub.status.busy": "2024-11-20T12:57:33.496852Z",
     "iopub.status.idle": "2024-11-20T12:57:33.501914Z",
     "shell.execute_reply": "2024-11-20T12:57:33.501146Z"
    },
    "papermill": {
     "duration": 0.011753,
     "end_time": "2024-11-20T12:57:33.503444",
     "exception": false,
     "start_time": "2024-11-20T12:57:33.491691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "folders_path = '/kaggle/input/audio-to-train-model/train-clean-100'\n",
    "\n",
    "# Wyciągam wszystkie podfoldery (ID osób) z głównego folderu z nagraniami.\n",
    "subfolders = [f.name for f in os.scandir(folders_path) if f.is_dir()]\n",
    "# Sortuję ID osób i zamieniam je z powrotem na stringi (ID muszą być w formie tekstowej).\n",
    "subfolders = sorted([int(item) for item in subfolders])\n",
    "subfolders = [str(item) for item in subfolders]\n",
    "\n",
    "# Tworzę pełne ścieżki do folderów dla każdego ID.\n",
    "paths_with_ID = [folders_path + '/' + subfolder for subfolder in subfolders]\n",
    "\n",
    "# Tworzę dwie ramki danych do przechowywania ID i sumarycznej długości nagrań dla kobiet i mężczyzn.\n",
    "data_frame_for_duration_woman = pd.DataFrame(columns=['ID', 'duration'])\n",
    "data_frame_for_duration_man = pd.DataFrame(columns=['ID', 'duration'])\n",
    "\n",
    "# Pętla przez wszystkie osoby, aby obliczyć sumaryczną długość nagrań.\n",
    "for path_with_ID in paths_with_ID:\n",
    "\n",
    "    # Zbieram ścieżki do folderów wewnątrz folderu danej osoby (podfoldery).\n",
    "    paths_inside_ID = [f.name for f in os.scandir(path_with_ID) if f.is_dir()]\n",
    "\n",
    "    # Tworzę pełne ścieżki do plików nagrań (plików .flac) dla każdego folderu wewnątrz ID.\n",
    "    full_paths_to_files = [path_with_ID + '/' + path_inside_ID for path_inside_ID in paths_inside_ID]\n",
    "\n",
    "    # Zbieram wszystkie pliki audio dla danej osoby.\n",
    "    all_files_for_ID = []\n",
    "    for full_path_to_files in full_paths_to_files:\n",
    "        files = [f.name for f in os.scandir(full_path_to_files) if f.is_file() and f.name.endswith('.flac')]\n",
    "        files = [full_path_to_files + '/' + file for file in files]\n",
    "        all_files_for_ID = all_files_for_ID + files\n",
    "\n",
    "    # Obliczam łączną długość nagrań danej osoby.\n",
    "    duration_in_seconds = 0\n",
    "    for file_for_ID in all_files_for_ID:\n",
    "        # Otwieram plik audio za pomocą SoundFile i obliczam długość nagrania na podstawie liczby próbek i częstotliwości próbkowania.\n",
    "        with sf.SoundFile(file_for_ID) as f:\n",
    "            frames = len(f)  # Liczba próbek (frames)\n",
    "            sample_rate = f.samplerate  # Częstotliwość próbkowania\n",
    "        duration = frames / sample_rate  # Długość nagrania w sekundach\n",
    "        duration_in_seconds = duration_in_seconds + duration  # Sumowanie długości wszystkich nagrań\n",
    "\n",
    "    # Wyciągam ID osoby z pełnej ścieżki.\n",
    "    ID = path_with_ID.split('/')[-1]\n",
    "    # Tworzę nowy rekord z ID i sumaryczną długością nagrań.\n",
    "    new_record = [ID, duration_in_seconds]\n",
    "    \n",
    "    # Sprawdzam, czy ID osoby należy do kobiet i dodaję dane do odpowiedniej ramki danych.\n",
    "    if np.isin(ID, df_woman['ID']):\n",
    "        data_frame_for_duration_woman.loc[len(data_frame_for_duration_woman)] = new_record\n",
    "    else:\n",
    "        data_frame_for_duration_man.loc[len(data_frame_for_duration_man)] = new_record\n",
    "\n",
    "    # Wyświetlam postęp pętli.\n",
    "    print(ID)\n",
    "    clear_output(wait=True)\n",
    "\n",
    "# Sortuję ramki danych według długości nagrań w kolejności malejącej.\n",
    "data_frame_for_duration_woman = data_frame_for_duration_woman.sort_values(by='duration', ascending=False)\n",
    "data_frame_for_duration_man = data_frame_for_duration_man.sort_values(by='duration', ascending=False)\n",
    "\n",
    "data_frame_for_duration_woman.to_csv('data_frame_for_duration_woman.csv', index=False)\n",
    "data_frame_for_duration_man.to_csv('data_frame_for_duration_man.csv', index=False)\n",
    "\n",
    "# Wybieram 50 kobiet i 50 mężczyzn o najdłuższej sumarycznej długości nagrań.\n",
    "man_to_train_UBM = data_frame_for_duration_man.head(50)\n",
    "woman_to_train_UBM = data_frame_for_duration_woman.head(50)\n",
    "\n",
    "man_to_test = data_frame_for_duration_man[50:75]\n",
    "woman_to_test = data_frame_for_duration_woman[50:75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6680adc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T12:57:33.513500Z",
     "iopub.status.busy": "2024-11-20T12:57:33.513211Z",
     "iopub.status.idle": "2024-11-20T12:57:33.516752Z",
     "shell.execute_reply": "2024-11-20T12:57:33.516052Z"
    },
    "papermill": {
     "duration": 0.00986,
     "end_time": "2024-11-20T12:57:33.518356",
     "exception": false,
     "start_time": "2024-11-20T12:57:33.508496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('man_to_train_UBM.pkl', 'wb') as file:\n",
    "    pickle.dump(man_to_train_UBM, file)\n",
    "\n",
    "with open('woman_to_train_UBM.pkl', 'wb') as file:\n",
    "    pickle.dump(woman_to_train_UBM, file)\n",
    "\n",
    "with open('man_to_test.pkl', 'wb') as file:\n",
    "    pickle.dump(man_to_test, file)\n",
    "\n",
    "with open('woman_to_test.pkl', 'wb') as file:\n",
    "    pickle.dump(woman_to_test, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c84e78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T12:57:33.527264Z",
     "iopub.status.busy": "2024-11-20T12:57:33.526985Z",
     "iopub.status.idle": "2024-11-20T12:57:33.530678Z",
     "shell.execute_reply": "2024-11-20T12:57:33.529883Z"
    },
    "papermill": {
     "duration": 0.009904,
     "end_time": "2024-11-20T12:57:33.532225",
     "exception": false,
     "start_time": "2024-11-20T12:57:33.522321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tworzę zbiory do trenowania modelu UBM i jego ewaluacji.\n",
    "\n",
    "folders_path = '/kaggle/input/audio-to-train-model/train-clean-100'\n",
    "\n",
    "top_50_man_paths = [folders_path + '/' + ID for ID in man_to_train_UBM['ID']]\n",
    "top_50_woman_paths = [folders_path + '/' + ID for ID in woman_to_train_UBM['ID']]\n",
    "\n",
    "data_to_train_UBM = top_50_man_paths + top_50_woman_paths\n",
    "\n",
    "with open(\"data_to_train_UBM.pkl\", \"wb\") as file:\n",
    "    pickle.dump(data_to_train_UBM, file)\n",
    "\n",
    "\n",
    "\n",
    "man_to_test = [folders_path + '/' + ID for ID in man_to_train_UBM['ID']]\n",
    "woman_to_test = [folders_path + '/' + ID for ID in woman_to_train_UBM['ID']]\n",
    "\n",
    "data_to_cross_checking = man_to_test + woman_to_test\n",
    "\n",
    "with open(\"data_to_cross_checking.pkl\", \"wb\") as file:\n",
    "    pickle.dump(data_to_cross_checking, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeb123a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T12:57:33.541582Z",
     "iopub.status.busy": "2024-11-20T12:57:33.541314Z",
     "iopub.status.idle": "2024-11-20T12:57:33.546121Z",
     "shell.execute_reply": "2024-11-20T12:57:33.545358Z"
    },
    "papermill": {
     "duration": 0.011162,
     "end_time": "2024-11-20T12:57:33.547641",
     "exception": false,
     "start_time": "2024-11-20T12:57:33.536479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Funkcja służy do dzielenia nagrań na krótkie nagrania o podanej długości i przy okazji liczy MFCC\n",
    "\n",
    "def split_audio_to_slices(path_to_files, seconds, iterator):\n",
    "    \n",
    "    # Przechodzę do katalogów wewnątrz folderu osoby (ID osoby).\n",
    "    # Każdy folder wewnętrzny zawiera więcej podfolderów, które mogą zawierać nagrania.\n",
    "    paths_inside_ID = [f.name for f in os.scandir(path_to_files) if f.is_dir()]\n",
    "\n",
    "    # Tworzę pełne ścieżki do podfolderów, aby przejść do wszystkich plików nagrań dla danej osoby.\n",
    "    full_paths_to_files = [path_to_files + '/' + path_inside_ID for path_inside_ID in paths_inside_ID]\n",
    "\n",
    "    # Zbieram wszystkie ścieżki do plików audio danej osoby.\n",
    "    # Każdy plik powinien mieć rozszerzenie `.flac`, a wszystkie pliki są przechowywane w zmiennej `all_files_for_ID`.\n",
    "\n",
    "    all_files_for_ID = []\n",
    "    \n",
    "    for full_path_to_files in full_paths_to_files:\n",
    "        files = [f.name for f in os.scandir(full_path_to_files) if f.is_file() and f.name.endswith('.flac')]\n",
    "        files = [full_path_to_files + '/' + file for file in files]\n",
    "        all_files_for_ID = all_files_for_ID + files\n",
    "\n",
    "    # Łączę wszystkie nagrania danej osoby w jedno bardzo długie nagranie.\n",
    "    # Używam częstotliwości próbkowania 16kHz (standardowe dla nagrań mowy).\n",
    "    sr = 16000\n",
    "    combined_signals = np.array([])\n",
    "\n",
    "    for file_for_ID in all_files_for_ID:\n",
    "        signal, sr = librosa.load(file_for_ID, sr=sr)\n",
    "        combined_signals = np.concatenate([combined_signals, signal])\n",
    "\n",
    "\n",
    "\n",
    "    # Długie nagranie dzielę na  fragmenty o podanej długości.\n",
    "    # Fragmenty, które mają mniej niż zadeklarowane długości nagrania (resztki na końcu nagrania), są pomijane.\n",
    "    list_for_parts = []\n",
    "    len_of_combined_signals = len(combined_signals)\n",
    "    step = seconds * sr  # Ustawienie skoku na 5 sekund\n",
    "    \n",
    "    for i in np.arange(start=0, stop=len_of_combined_signals-step, step=step):\n",
    "        list_for_parts.append(combined_signals[i:i+step].tolist())\n",
    "\n",
    "    parts = np.array(list_for_parts)\n",
    "\n",
    "    \n",
    "\n",
    "    # Liczba współczynników MFCC, które zostaną wyliczone dla każdego fragmentu nagrania (standardowe 13 współczynników).\n",
    "    quantity_of_mel_coef = 40\n",
    "    # Liczba filtrów melowych, które określają, ile \"czapek\" melowych zostanie użytych do przetwarzania sygnału.\n",
    "    quantity_of_mel_filters = 60\n",
    "\n",
    "    # Tworzę listy na współczynniki MFCC dla zbiorów uczącego i testowego.\n",
    "    mfcc_list = []\n",
    "\n",
    "    # Dla każdego fragmentu w zbiorze uczącym liczę współczynniki MFCC.\n",
    "    for i in range(0, len(parts)):\n",
    "        mfcc = librosa.feature.mfcc(y=parts[i], \n",
    "                                    sr=16000, \n",
    "                                    n_mfcc=quantity_of_mel_coef, \n",
    "                                    n_mels=quantity_of_mel_filters).T\n",
    "        mfcc_list.append(mfcc)\n",
    "        print(iterator + i/len(parts))\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    mfcc_data = np.array(mfcc_list)\n",
    "\n",
    "    # Funkcja zwraca MFCC dla nagrań o długości jednej sekundy\n",
    "    return mfcc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c710973",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T12:57:33.556684Z",
     "iopub.status.busy": "2024-11-20T12:57:33.556457Z",
     "iopub.status.idle": "2024-11-20T12:57:33.559927Z",
     "shell.execute_reply": "2024-11-20T12:57:33.559198Z"
    },
    "papermill": {
     "duration": 0.009773,
     "end_time": "2024-11-20T12:57:33.561531",
     "exception": false,
     "start_time": "2024-11-20T12:57:33.551758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lista będzie przechowywać króciutkie nagrania, druga z nich natomiast będzie informować kto jest właścicielem nagrania.\n",
    "mfcc_train_list = []\n",
    "owner_of_audio = []\n",
    "\n",
    "for i in range(0, 100):\n",
    "    \n",
    "    # Wywołuję funkcję split_train_test_data, aby podzielić nagrania danej osoby na zbiory treningowe i testowe.\n",
    "    train_mfcc = split_audio_to_slices(data_to_train_UBM[i], 1, i)\n",
    "    mfcc_train_list.extend(train_mfcc)\n",
    "    \n",
    "    owner_of_audio.extend([i] * len(train_mfcc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd17cc60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T12:57:33.570471Z",
     "iopub.status.busy": "2024-11-20T12:57:33.570176Z",
     "iopub.status.idle": "2024-11-20T12:57:33.573710Z",
     "shell.execute_reply": "2024-11-20T12:57:33.572897Z"
    },
    "papermill": {
     "duration": 0.009725,
     "end_time": "2024-11-20T12:57:33.575218",
     "exception": false,
     "start_time": "2024-11-20T12:57:33.565493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Liczę pochodne MFCC aby model lepiej się nauczył\n",
    "\n",
    "for i in range(0, len(mfcc_train_list)):\n",
    "    delta = librosa.feature.delta(mfcc_train_list[i])\n",
    "    delta2 = librosa.feature.delta(mfcc_train_list[i], order=2)\n",
    "\n",
    "    one_audio = np.hstack([mfcc_train_list[i], delta, delta2])\n",
    "    mfcc_train_list[i] = one_audio\n",
    "\n",
    "    print(i/len(mfcc_train_list))\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0506e99d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T12:57:33.584168Z",
     "iopub.status.busy": "2024-11-20T12:57:33.583933Z",
     "iopub.status.idle": "2024-11-20T12:57:33.587198Z",
     "shell.execute_reply": "2024-11-20T12:57:33.586567Z"
    },
    "papermill": {
     "duration": 0.009476,
     "end_time": "2024-11-20T12:57:33.588661",
     "exception": false,
     "start_time": "2024-11-20T12:57:33.579185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('mfcc_train_list.pkl', 'wb') as file:\n",
    "    pickle.dump(mfcc_train_list, file)\n",
    "\n",
    "with open('owner_of_audio.pkl', 'wb') as file:\n",
    "    pickle.dump(owner_of_audio, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bf26a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T12:57:33.597466Z",
     "iopub.status.busy": "2024-11-20T12:57:33.597191Z",
     "iopub.status.idle": "2024-11-20T12:57:33.600473Z",
     "shell.execute_reply": "2024-11-20T12:57:33.599774Z"
    },
    "papermill": {
     "duration": 0.009377,
     "end_time": "2024-11-20T12:57:33.601972",
     "exception": false,
     "start_time": "2024-11-20T12:57:33.592595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('/kaggle/input/data-to-train-rnn/data_RNN/mfcc_train_list.pkl', 'rb') as file:\n",
    "    mfcc_train_list = pickle.load(file)\n",
    "\n",
    "with open('/kaggle/input/data-to-train-rnn/data_RNN/owner_of_audio.pkl', 'rb') as file:\n",
    "    owner_of_audio = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b559e471",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T12:57:33.610991Z",
     "iopub.status.busy": "2024-11-20T12:57:33.610517Z",
     "iopub.status.idle": "2024-11-20T12:57:33.614076Z",
     "shell.execute_reply": "2024-11-20T12:57:33.613436Z"
    },
    "papermill": {
     "duration": 0.009714,
     "end_time": "2024-11-20T12:57:33.615525",
     "exception": false,
     "start_time": "2024-11-20T12:57:33.605811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Liczę skaler aby sieć dobrze się wytrenowała\n",
    "\n",
    "commmon_df_for_train = np.concatenate(mfcc_train_list, axis=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(commmon_df_for_train)\n",
    "\n",
    "X_train = [scaler.transform(one_audio) for one_audio in mfcc_train_list]\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "train_owner = np.array(owner_of_audio)\n",
    "\n",
    "with open(\"scaler.pkl\", \"wb\") as file:\n",
    "    pickle.dump(scaler, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcde079",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T12:57:33.624093Z",
     "iopub.status.busy": "2024-11-20T12:57:33.623879Z",
     "iopub.status.idle": "2024-11-20T12:57:33.627191Z",
     "shell.execute_reply": "2024-11-20T12:57:33.626559Z"
    },
    "papermill": {
     "duration": 0.009315,
     "end_time": "2024-11-20T12:57:33.628705",
     "exception": false,
     "start_time": "2024-11-20T12:57:33.619390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Wydzielam zbiór treningowy i walidacyjny do modelu\n",
    "train_size = int(np.floor(len(X_train) * 0.8))\n",
    "\n",
    "# Losowy wybór indeksów, które zostaną użyte jako dane treningowe (80% próbek).\n",
    "index_of_train = np.random.choice(np.arange(0, len(X_train)), size=train_size, replace=False)\n",
    "\n",
    "# Reszta indeksów (20% próbek będzie zbiorem walidacyjnym)\n",
    "rest_of_index = ~np.isin(np.arange(0, len(X_train)), index_of_train)\n",
    "\n",
    "X_valid = X_train[rest_of_index]\n",
    "X_train = X_train[index_of_train]\n",
    "\n",
    "valid_owner = train_owner[rest_of_index]\n",
    "train_owner = train_owner[index_of_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e717d3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T12:57:33.637594Z",
     "iopub.status.busy": "2024-11-20T12:57:33.637139Z",
     "iopub.status.idle": "2024-11-20T12:57:33.640927Z",
     "shell.execute_reply": "2024-11-20T12:57:33.640214Z"
    },
    "papermill": {
     "duration": 0.009887,
     "end_time": "2024-11-20T12:57:33.642476",
     "exception": false,
     "start_time": "2024-11-20T12:57:33.632589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Przekształcam dane treningowe (X_train), aby miały odpowiedni kształt dla sieci CNN.\n",
    "# Dodaję nowy wymiar (1) na końcu, ponieważ sieci konwolucyjne oczekują wejść o formacie 4D:\n",
    "# (liczba próbek, wysokość, szerokość, liczba kanałów). Tutaj mamy 1 kanał (monofoniczne nagrania).\n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0], \n",
    "                           X_train.shape[1], \n",
    "                           X_train.shape[2], \n",
    "                           1))\n",
    "\n",
    "# Przekształcam dane walidacyjne (X_valid) do tego samego formatu 4D co dane treningowe.\n",
    "X_valid = X_valid.reshape((X_valid.shape[0], \n",
    "                           X_valid.shape[1], \n",
    "                           X_valid.shape[2], \n",
    "                           1))\n",
    "\n",
    "\n",
    "\n",
    "# Konwertuję etykiety dla zestawu treningowego (train_owner) na postać one-hot encoding dla klasyfikacji wieloklasowej (100 klas).\n",
    "# Używam funkcji to_categorical, aby zamienić numeryczne etykiety (ID osób) na macierze o rozmiarze [100], gdzie \n",
    "# każda wartość reprezentuje prawdopodobieństwo przynależności do danej klasy.\n",
    "y_train = to_categorical(train_owner, num_classes=100)\n",
    "\n",
    "# Podobnie konwertuję etykiety dla zestawu walidacyjnego na one-hot encoding.\n",
    "y_valid = to_categorical(valid_owner, num_classes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaebe71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T12:57:33.652028Z",
     "iopub.status.busy": "2024-11-20T12:57:33.651413Z",
     "iopub.status.idle": "2024-11-20T12:57:33.654874Z",
     "shell.execute_reply": "2024-11-20T12:57:33.654075Z"
    },
    "papermill": {
     "duration": 0.00988,
     "end_time": "2024-11-20T12:57:33.656439",
     "exception": false,
     "start_time": "2024-11-20T12:57:33.646559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.save('X_train.npy', X_train)\n",
    "np.save('X_valid.npy', X_valid)\n",
    "\n",
    "np.save('y_train.npy', y_train)\n",
    "np.save('y_valid.npy', y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef3ab4d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T12:57:33.665464Z",
     "iopub.status.busy": "2024-11-20T12:57:33.664925Z",
     "iopub.status.idle": "2024-11-20T12:57:54.672109Z",
     "shell.execute_reply": "2024-11-20T12:57:54.671383Z"
    },
    "papermill": {
     "duration": 21.013894,
     "end_time": "2024-11-20T12:57:54.674293",
     "exception": false,
     "start_time": "2024-11-20T12:57:33.660399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = np.load('/kaggle/input/train-valid-data-to-train-rnn/X_train.npy')\n",
    "X_valid = np.load('/kaggle/input/train-valid-data-to-train-rnn/X_valid.npy')\n",
    "\n",
    "y_train = np.load('/kaggle/input/train-valid-data-to-train-rnn/y_train.npy')\n",
    "y_valid = np.load('/kaggle/input/train-valid-data-to-train-rnn/y_valid.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b57e4de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T12:57:54.683955Z",
     "iopub.status.busy": "2024-11-20T12:57:54.683662Z",
     "iopub.status.idle": "2024-11-20T12:57:54.688922Z",
     "shell.execute_reply": "2024-11-20T12:57:54.688093Z"
    },
    "papermill": {
     "duration": 0.011832,
     "end_time": "2024-11-20T12:57:54.690483",
     "exception": false,
     "start_time": "2024-11-20T12:57:54.678651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Niestandardowy callback do mierzenia czasu\n",
    "class TimeHistory(Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.times = []  # Lista do przechowywania czasu dla każdej epoki\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.epoch_start_time = time.time()  # Zapis początku epoki\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        epoch_time = time.time() - self.epoch_start_time  # Czas trwania epoki\n",
    "        self.times.append(epoch_time)  # Dodanie czasu do listy\n",
    "        if epoch < 20:  \n",
    "            print(f\"Czas dla epoki {epoch + 1}: {epoch_time:.2f} sekundy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8539390",
   "metadata": {},
   "source": [
    "# LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c95dca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T12:57:54.699557Z",
     "iopub.status.busy": "2024-11-20T12:57:54.699280Z",
     "iopub.status.idle": "2024-11-20T14:03:15.178314Z",
     "shell.execute_reply": "2024-11-20T14:03:15.177248Z"
    },
    "papermill": {
     "duration": 3923.565896,
     "end_time": "2024-11-20T14:03:18.260431",
     "exception": false,
     "start_time": "2024-11-20T12:57:54.694535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">47,360</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bottleneck (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,900</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m47,360\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m12,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │        \u001b[38;5;34m33,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │         \u001b[38;5;34m4,096\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m524,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bottleneck (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m12,900\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">803,044</span> (3.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m803,044\u001b[0m (3.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">799,268</span> (3.05 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m799,268\u001b[0m (3.05 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,776</span> (14.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,776\u001b[0m (14.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m3774/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3793 - loss: 2.5601Czas dla epoki 1: 55.98 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 13ms/step - accuracy: 0.3794 - loss: 2.5596 - val_accuracy: 0.8652 - val_loss: 0.4507 - learning_rate: 0.0010\n",
      "Epoch 2/200\n",
      "\u001b[1m3773/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8134 - loss: 0.6428Czas dla epoki 2: 48.10 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 13ms/step - accuracy: 0.8134 - loss: 0.6428 - val_accuracy: 0.9230 - val_loss: 0.2524 - learning_rate: 0.0010\n",
      "Epoch 3/200\n",
      "\u001b[1m3772/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8787 - loss: 0.4164Czas dla epoki 3: 48.93 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 13ms/step - accuracy: 0.8787 - loss: 0.4164 - val_accuracy: 0.9433 - val_loss: 0.1873 - learning_rate: 0.0010\n",
      "Epoch 4/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9026 - loss: 0.3323Czas dla epoki 4: 48.46 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 13ms/step - accuracy: 0.9026 - loss: 0.3323 - val_accuracy: 0.9550 - val_loss: 0.1539 - learning_rate: 0.0010\n",
      "Epoch 5/200\n",
      "\u001b[1m3771/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9190 - loss: 0.2725Czas dla epoki 5: 48.75 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 13ms/step - accuracy: 0.9190 - loss: 0.2725 - val_accuracy: 0.9613 - val_loss: 0.1298 - learning_rate: 0.0010\n",
      "Epoch 6/200\n",
      "\u001b[1m3774/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9280 - loss: 0.2424Czas dla epoki 6: 48.07 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 13ms/step - accuracy: 0.9280 - loss: 0.2424 - val_accuracy: 0.9713 - val_loss: 0.0977 - learning_rate: 0.0010\n",
      "Epoch 7/200\n",
      "\u001b[1m3774/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9355 - loss: 0.2127Czas dla epoki 7: 47.95 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 13ms/step - accuracy: 0.9355 - loss: 0.2127 - val_accuracy: 0.9717 - val_loss: 0.0949 - learning_rate: 0.0010\n",
      "Epoch 8/200\n",
      "\u001b[1m3771/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9399 - loss: 0.1968Czas dla epoki 8: 47.80 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 13ms/step - accuracy: 0.9399 - loss: 0.1968 - val_accuracy: 0.9743 - val_loss: 0.0873 - learning_rate: 0.0010\n",
      "Epoch 9/200\n",
      "\u001b[1m3772/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9449 - loss: 0.1826Czas dla epoki 9: 47.76 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 13ms/step - accuracy: 0.9449 - loss: 0.1826 - val_accuracy: 0.9741 - val_loss: 0.0852 - learning_rate: 0.0010\n",
      "Epoch 10/200\n",
      "\u001b[1m3773/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9503 - loss: 0.1672Czas dla epoki 10: 48.03 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 13ms/step - accuracy: 0.9503 - loss: 0.1672 - val_accuracy: 0.9753 - val_loss: 0.0845 - learning_rate: 0.0010\n",
      "Epoch 11/200\n",
      "\u001b[1m3773/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9507 - loss: 0.1627Czas dla epoki 11: 49.24 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 13ms/step - accuracy: 0.9507 - loss: 0.1627 - val_accuracy: 0.9774 - val_loss: 0.0762 - learning_rate: 0.0010\n",
      "Epoch 12/200\n",
      "\u001b[1m3773/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9549 - loss: 0.1505Czas dla epoki 12: 49.07 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 13ms/step - accuracy: 0.9549 - loss: 0.1505 - val_accuracy: 0.9782 - val_loss: 0.0737 - learning_rate: 0.0010\n",
      "Epoch 13/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9566 - loss: 0.1432Czas dla epoki 13: 49.36 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 13ms/step - accuracy: 0.9566 - loss: 0.1432 - val_accuracy: 0.9781 - val_loss: 0.0744 - learning_rate: 0.0010\n",
      "Epoch 14/200\n",
      "\u001b[1m3772/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9589 - loss: 0.1329Czas dla epoki 14: 48.33 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 13ms/step - accuracy: 0.9589 - loss: 0.1329 - val_accuracy: 0.9774 - val_loss: 0.0770 - learning_rate: 0.0010\n",
      "Epoch 15/200\n",
      "\u001b[1m3773/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9606 - loss: 0.1311Czas dla epoki 15: 48.22 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 13ms/step - accuracy: 0.9606 - loss: 0.1311 - val_accuracy: 0.9818 - val_loss: 0.0651 - learning_rate: 0.0010\n",
      "Epoch 16/200\n",
      "\u001b[1m3774/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9613 - loss: 0.1260Czas dla epoki 16: 48.15 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 13ms/step - accuracy: 0.9613 - loss: 0.1260 - val_accuracy: 0.9807 - val_loss: 0.0675 - learning_rate: 0.0010\n",
      "Epoch 17/200\n",
      "\u001b[1m3771/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9625 - loss: 0.1236Czas dla epoki 17: 48.25 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 13ms/step - accuracy: 0.9625 - loss: 0.1236 - val_accuracy: 0.9810 - val_loss: 0.0655 - learning_rate: 0.0010\n",
      "Epoch 18/200\n",
      "\u001b[1m3774/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9637 - loss: 0.1190Czas dla epoki 18: 48.47 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 13ms/step - accuracy: 0.9637 - loss: 0.1190 - val_accuracy: 0.9826 - val_loss: 0.0595 - learning_rate: 0.0010\n",
      "Epoch 19/200\n",
      "\u001b[1m3771/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9637 - loss: 0.1169Czas dla epoki 19: 48.32 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 13ms/step - accuracy: 0.9637 - loss: 0.1169 - val_accuracy: 0.9799 - val_loss: 0.0670 - learning_rate: 0.0010\n",
      "Epoch 20/200\n",
      "\u001b[1m3772/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9652 - loss: 0.1116Czas dla epoki 20: 48.66 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 13ms/step - accuracy: 0.9652 - loss: 0.1116 - val_accuracy: 0.9801 - val_loss: 0.0693 - learning_rate: 0.0010\n",
      "Epoch 21/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 13ms/step - accuracy: 0.9659 - loss: 0.1105 - val_accuracy: 0.9813 - val_loss: 0.0621 - learning_rate: 0.0010\n",
      "Epoch 22/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 13ms/step - accuracy: 0.9684 - loss: 0.1046 - val_accuracy: 0.9831 - val_loss: 0.0588 - learning_rate: 0.0010\n",
      "Epoch 23/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 13ms/step - accuracy: 0.9684 - loss: 0.1050 - val_accuracy: 0.9830 - val_loss: 0.0581 - learning_rate: 0.0010\n",
      "Epoch 24/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.1033 - val_accuracy: 0.9815 - val_loss: 0.0595 - learning_rate: 0.0010\n",
      "Epoch 25/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 13ms/step - accuracy: 0.9700 - loss: 0.0976 - val_accuracy: 0.9822 - val_loss: 0.0593 - learning_rate: 0.0010\n",
      "Epoch 26/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 13ms/step - accuracy: 0.9685 - loss: 0.1012 - val_accuracy: 0.9825 - val_loss: 0.0568 - learning_rate: 0.0010\n",
      "Epoch 27/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 13ms/step - accuracy: 0.9709 - loss: 0.0959 - val_accuracy: 0.9836 - val_loss: 0.0573 - learning_rate: 0.0010\n",
      "Epoch 28/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 13ms/step - accuracy: 0.9710 - loss: 0.0936 - val_accuracy: 0.9841 - val_loss: 0.0557 - learning_rate: 0.0010\n",
      "Epoch 29/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 13ms/step - accuracy: 0.9710 - loss: 0.0929 - val_accuracy: 0.9831 - val_loss: 0.0577 - learning_rate: 0.0010\n",
      "Epoch 30/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 13ms/step - accuracy: 0.9724 - loss: 0.0883 - val_accuracy: 0.9838 - val_loss: 0.0525 - learning_rate: 0.0010\n",
      "Epoch 31/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 13ms/step - accuracy: 0.9715 - loss: 0.0921 - val_accuracy: 0.9849 - val_loss: 0.0558 - learning_rate: 0.0010\n",
      "Epoch 32/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 13ms/step - accuracy: 0.9731 - loss: 0.0898 - val_accuracy: 0.9831 - val_loss: 0.0566 - learning_rate: 0.0010\n",
      "Epoch 33/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 13ms/step - accuracy: 0.9731 - loss: 0.0860 - val_accuracy: 0.9837 - val_loss: 0.0558 - learning_rate: 0.0010\n",
      "Epoch 34/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 13ms/step - accuracy: 0.9722 - loss: 0.0878 - val_accuracy: 0.9811 - val_loss: 0.0650 - learning_rate: 0.0010\n",
      "Epoch 35/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 13ms/step - accuracy: 0.9728 - loss: 0.0900 - val_accuracy: 0.9846 - val_loss: 0.0530 - learning_rate: 0.0010\n",
      "Epoch 36/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 13ms/step - accuracy: 0.9802 - loss: 0.0628 - val_accuracy: 0.9875 - val_loss: 0.0433 - learning_rate: 5.0000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 13ms/step - accuracy: 0.9826 - loss: 0.0549 - val_accuracy: 0.9884 - val_loss: 0.0394 - learning_rate: 5.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 13ms/step - accuracy: 0.9829 - loss: 0.0528 - val_accuracy: 0.9885 - val_loss: 0.0403 - learning_rate: 5.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 13ms/step - accuracy: 0.9838 - loss: 0.0513 - val_accuracy: 0.9879 - val_loss: 0.0428 - learning_rate: 5.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 13ms/step - accuracy: 0.9848 - loss: 0.0483 - val_accuracy: 0.9872 - val_loss: 0.0433 - learning_rate: 5.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 13ms/step - accuracy: 0.9844 - loss: 0.0496 - val_accuracy: 0.9887 - val_loss: 0.0384 - learning_rate: 5.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 13ms/step - accuracy: 0.9857 - loss: 0.0460 - val_accuracy: 0.9886 - val_loss: 0.0410 - learning_rate: 5.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 13ms/step - accuracy: 0.9848 - loss: 0.0481 - val_accuracy: 0.9892 - val_loss: 0.0397 - learning_rate: 5.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 13ms/step - accuracy: 0.9861 - loss: 0.0440 - val_accuracy: 0.9886 - val_loss: 0.0420 - learning_rate: 5.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 13ms/step - accuracy: 0.9852 - loss: 0.0454 - val_accuracy: 0.9889 - val_loss: 0.0404 - learning_rate: 5.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 13ms/step - accuracy: 0.9860 - loss: 0.0438 - val_accuracy: 0.9880 - val_loss: 0.0425 - learning_rate: 5.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 13ms/step - accuracy: 0.9879 - loss: 0.0397 - val_accuracy: 0.9904 - val_loss: 0.0363 - learning_rate: 2.5000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 13ms/step - accuracy: 0.9896 - loss: 0.0329 - val_accuracy: 0.9907 - val_loss: 0.0354 - learning_rate: 2.5000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 13ms/step - accuracy: 0.9900 - loss: 0.0314 - val_accuracy: 0.9905 - val_loss: 0.0349 - learning_rate: 2.5000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 13ms/step - accuracy: 0.9907 - loss: 0.0298 - val_accuracy: 0.9902 - val_loss: 0.0362 - learning_rate: 2.5000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 13ms/step - accuracy: 0.9914 - loss: 0.0270 - val_accuracy: 0.9901 - val_loss: 0.0367 - learning_rate: 2.5000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 13ms/step - accuracy: 0.9902 - loss: 0.0289 - val_accuracy: 0.9906 - val_loss: 0.0371 - learning_rate: 2.5000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 13ms/step - accuracy: 0.9914 - loss: 0.0262 - val_accuracy: 0.9909 - val_loss: 0.0346 - learning_rate: 2.5000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 13ms/step - accuracy: 0.9909 - loss: 0.0287 - val_accuracy: 0.9903 - val_loss: 0.0371 - learning_rate: 2.5000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 13ms/step - accuracy: 0.9911 - loss: 0.0280 - val_accuracy: 0.9909 - val_loss: 0.0361 - learning_rate: 2.5000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 13ms/step - accuracy: 0.9916 - loss: 0.0268 - val_accuracy: 0.9908 - val_loss: 0.0345 - learning_rate: 2.5000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 13ms/step - accuracy: 0.9918 - loss: 0.0264 - val_accuracy: 0.9901 - val_loss: 0.0393 - learning_rate: 2.5000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 13ms/step - accuracy: 0.9921 - loss: 0.0253 - val_accuracy: 0.9902 - val_loss: 0.0384 - learning_rate: 2.5000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 13ms/step - accuracy: 0.9917 - loss: 0.0254 - val_accuracy: 0.9903 - val_loss: 0.0380 - learning_rate: 2.5000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 13ms/step - accuracy: 0.9918 - loss: 0.0249 - val_accuracy: 0.9908 - val_loss: 0.0376 - learning_rate: 2.5000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 13ms/step - accuracy: 0.9915 - loss: 0.0260 - val_accuracy: 0.9907 - val_loss: 0.0365 - learning_rate: 2.5000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 13ms/step - accuracy: 0.9928 - loss: 0.0219 - val_accuracy: 0.9915 - val_loss: 0.0344 - learning_rate: 1.2500e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 13ms/step - accuracy: 0.9931 - loss: 0.0211 - val_accuracy: 0.9911 - val_loss: 0.0356 - learning_rate: 1.2500e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 13ms/step - accuracy: 0.9937 - loss: 0.0199 - val_accuracy: 0.9916 - val_loss: 0.0342 - learning_rate: 1.2500e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 13ms/step - accuracy: 0.9933 - loss: 0.0202 - val_accuracy: 0.9917 - val_loss: 0.0336 - learning_rate: 1.2500e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 13ms/step - accuracy: 0.9937 - loss: 0.0192 - val_accuracy: 0.9916 - val_loss: 0.0342 - learning_rate: 1.2500e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 13ms/step - accuracy: 0.9936 - loss: 0.0196 - val_accuracy: 0.9917 - val_loss: 0.0329 - learning_rate: 1.2500e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 14ms/step - accuracy: 0.9939 - loss: 0.0183 - val_accuracy: 0.9914 - val_loss: 0.0333 - learning_rate: 1.2500e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9937 - loss: 0.0188 - val_accuracy: 0.9916 - val_loss: 0.0328 - learning_rate: 1.2500e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 14ms/step - accuracy: 0.9940 - loss: 0.0180 - val_accuracy: 0.9919 - val_loss: 0.0335 - learning_rate: 1.2500e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9945 - loss: 0.0169 - val_accuracy: 0.9919 - val_loss: 0.0332 - learning_rate: 1.2500e-04\n",
      "Epoch 72/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9944 - loss: 0.0171 - val_accuracy: 0.9918 - val_loss: 0.0341 - learning_rate: 1.2500e-04\n",
      "Epoch 73/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9940 - loss: 0.0185 - val_accuracy: 0.9918 - val_loss: 0.0346 - learning_rate: 1.2500e-04\n",
      "Epoch 74/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 14ms/step - accuracy: 0.9938 - loss: 0.0185 - val_accuracy: 0.9918 - val_loss: 0.0341 - learning_rate: 1.2500e-04\n",
      "Epoch 75/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9947 - loss: 0.0165 - val_accuracy: 0.9921 - val_loss: 0.0333 - learning_rate: 6.2500e-05\n",
      "Epoch 76/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 14ms/step - accuracy: 0.9949 - loss: 0.0152 - val_accuracy: 0.9924 - val_loss: 0.0332 - learning_rate: 6.2500e-05\n",
      "Epoch 77/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9950 - loss: 0.0151 - val_accuracy: 0.9924 - val_loss: 0.0331 - learning_rate: 6.2500e-05\n",
      "Epoch 78/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9951 - loss: 0.0155 - val_accuracy: 0.9924 - val_loss: 0.0336 - learning_rate: 6.2500e-05\n",
      "Epoch 79/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9951 - loss: 0.0147 - val_accuracy: 0.9923 - val_loss: 0.0337 - learning_rate: 6.2500e-05\n"
     ]
    }
   ],
   "source": [
    "# Wykrozystam stworzony callback aby zbadać który model najszybciej się uczy\n",
    "time_callback = TimeHistory()\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(64, input_shape=(32, 120), return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(LSTM(32, return_sequences=False))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Dense(128, activation='linear', name='bottleneck'))\n",
    "\n",
    "\n",
    "model.add(Dense(100, activation='softmax'))  \n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-8)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,    \n",
    "    y_train,    \n",
    "    epochs=200,  \n",
    "    batch_size=32,  \n",
    "    verbose=1,\n",
    "    validation_data=(X_valid, y_valid),  \n",
    "    callbacks=[reduce_lr, early_stopping, time_callback]  \n",
    ")\n",
    "\n",
    "LSTM_time = sum(time_callback.times[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b525fad1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T14:03:24.653169Z",
     "iopub.status.busy": "2024-11-20T14:03:24.652825Z",
     "iopub.status.idle": "2024-11-20T14:03:24.734348Z",
     "shell.execute_reply": "2024-11-20T14:03:24.733427Z"
    },
    "papermill": {
     "duration": 3.334803,
     "end_time": "2024-11-20T14:03:24.736333",
     "exception": false,
     "start_time": "2024-11-20T14:03:21.401530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('model_LSTM.h5')\n",
    "np.save('LSTM_time.npy', LSTM_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4041de7a",
   "metadata": {},
   "source": [
    "# GRU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df358f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T14:03:31.276491Z",
     "iopub.status.busy": "2024-11-20T14:03:31.275813Z",
     "iopub.status.idle": "2024-11-20T15:15:12.078589Z",
     "shell.execute_reply": "2024-11-20T15:15:12.077834Z"
    },
    "papermill": {
     "duration": 4304.037321,
     "end_time": "2024-11-20T15:15:12.080706",
     "exception": false,
     "start_time": "2024-11-20T14:03:28.043385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">35,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bottleneck (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,900</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m35,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m9,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │        \u001b[38;5;34m33,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │         \u001b[38;5;34m4,096\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m524,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bottleneck (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m12,900\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">788,388</span> (3.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m788,388\u001b[0m (3.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">784,612</span> (2.99 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m784,612\u001b[0m (2.99 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,776</span> (14.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,776\u001b[0m (14.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m3771/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4096 - loss: 2.4371Czas dla epoki 1: 56.62 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 14ms/step - accuracy: 0.4098 - loss: 2.4358 - val_accuracy: 0.9125 - val_loss: 0.2878 - learning_rate: 0.0010\n",
      "Epoch 2/200\n",
      "\u001b[1m3774/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8336 - loss: 0.5547Czas dla epoki 2: 51.67 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.8336 - loss: 0.5547 - val_accuracy: 0.9393 - val_loss: 0.1966 - learning_rate: 0.0010\n",
      "Epoch 3/200\n",
      "\u001b[1m3773/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8790 - loss: 0.4055Czas dla epoki 3: 51.25 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 14ms/step - accuracy: 0.8790 - loss: 0.4055 - val_accuracy: 0.9572 - val_loss: 0.1422 - learning_rate: 0.0010\n",
      "Epoch 4/200\n",
      "\u001b[1m3774/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9004 - loss: 0.3307Czas dla epoki 4: 51.74 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9004 - loss: 0.3307 - val_accuracy: 0.9650 - val_loss: 0.1159 - learning_rate: 0.0010\n",
      "Epoch 5/200\n",
      "\u001b[1m3773/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9135 - loss: 0.2836Czas dla epoki 5: 51.19 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 14ms/step - accuracy: 0.9135 - loss: 0.2836 - val_accuracy: 0.9667 - val_loss: 0.1082 - learning_rate: 0.0010\n",
      "Epoch 6/200\n",
      "\u001b[1m3771/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9238 - loss: 0.2522Czas dla epoki 6: 51.47 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 14ms/step - accuracy: 0.9238 - loss: 0.2522 - val_accuracy: 0.9713 - val_loss: 0.0923 - learning_rate: 0.0010\n",
      "Epoch 7/200\n",
      "\u001b[1m3773/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9310 - loss: 0.2297Czas dla epoki 7: 48.84 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 13ms/step - accuracy: 0.9310 - loss: 0.2297 - val_accuracy: 0.9697 - val_loss: 0.1003 - learning_rate: 0.0010\n",
      "Epoch 8/200\n",
      "\u001b[1m3772/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9349 - loss: 0.2107Czas dla epoki 8: 51.78 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9349 - loss: 0.2107 - val_accuracy: 0.9723 - val_loss: 0.0908 - learning_rate: 0.0010\n",
      "Epoch 9/200\n",
      "\u001b[1m3774/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9389 - loss: 0.1995Czas dla epoki 9: 51.46 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 14ms/step - accuracy: 0.9389 - loss: 0.1995 - val_accuracy: 0.9760 - val_loss: 0.0776 - learning_rate: 0.0010\n",
      "Epoch 10/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9437 - loss: 0.1829Czas dla epoki 10: 51.94 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9437 - loss: 0.1829 - val_accuracy: 0.9784 - val_loss: 0.0680 - learning_rate: 0.0010\n",
      "Epoch 11/200\n",
      "\u001b[1m3774/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9476 - loss: 0.1742Czas dla epoki 11: 50.96 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 13ms/step - accuracy: 0.9476 - loss: 0.1742 - val_accuracy: 0.9793 - val_loss: 0.0696 - learning_rate: 0.0010\n",
      "Epoch 12/200\n",
      "\u001b[1m3774/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9488 - loss: 0.1669Czas dla epoki 12: 51.97 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9488 - loss: 0.1669 - val_accuracy: 0.9799 - val_loss: 0.0649 - learning_rate: 0.0010\n",
      "Epoch 13/200\n",
      "\u001b[1m3774/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9529 - loss: 0.1566Czas dla epoki 13: 51.57 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9529 - loss: 0.1566 - val_accuracy: 0.9791 - val_loss: 0.0651 - learning_rate: 0.0010\n",
      "Epoch 14/200\n",
      "\u001b[1m3771/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9530 - loss: 0.1516Czas dla epoki 14: 51.50 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9530 - loss: 0.1516 - val_accuracy: 0.9802 - val_loss: 0.0659 - learning_rate: 0.0010\n",
      "Epoch 15/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9543 - loss: 0.1501Czas dla epoki 15: 52.53 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 14ms/step - accuracy: 0.9543 - loss: 0.1501 - val_accuracy: 0.9809 - val_loss: 0.0623 - learning_rate: 0.0010\n",
      "Epoch 16/200\n",
      "\u001b[1m3773/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9560 - loss: 0.1417Czas dla epoki 16: 51.33 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 14ms/step - accuracy: 0.9560 - loss: 0.1417 - val_accuracy: 0.9824 - val_loss: 0.0566 - learning_rate: 0.0010\n",
      "Epoch 17/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9579 - loss: 0.1367Czas dla epoki 17: 52.22 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9579 - loss: 0.1367 - val_accuracy: 0.9820 - val_loss: 0.0582 - learning_rate: 0.0010\n",
      "Epoch 18/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9582 - loss: 0.1337Czas dla epoki 18: 51.87 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9582 - loss: 0.1337 - val_accuracy: 0.9835 - val_loss: 0.0537 - learning_rate: 0.0010\n",
      "Epoch 19/200\n",
      "\u001b[1m3772/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9602 - loss: 0.1295Czas dla epoki 19: 52.11 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9602 - loss: 0.1295 - val_accuracy: 0.9835 - val_loss: 0.0541 - learning_rate: 0.0010\n",
      "Epoch 20/200\n",
      "\u001b[1m3774/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9611 - loss: 0.1242Czas dla epoki 20: 51.55 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9611 - loss: 0.1243 - val_accuracy: 0.9844 - val_loss: 0.0520 - learning_rate: 0.0010\n",
      "Epoch 21/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9615 - loss: 0.1253 - val_accuracy: 0.9849 - val_loss: 0.0518 - learning_rate: 0.0010\n",
      "Epoch 22/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9634 - loss: 0.1174 - val_accuracy: 0.9846 - val_loss: 0.0511 - learning_rate: 0.0010\n",
      "Epoch 23/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9617 - loss: 0.1193 - val_accuracy: 0.9855 - val_loss: 0.0458 - learning_rate: 0.0010\n",
      "Epoch 24/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 14ms/step - accuracy: 0.9641 - loss: 0.1143 - val_accuracy: 0.9832 - val_loss: 0.0548 - learning_rate: 0.0010\n",
      "Epoch 25/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9644 - loss: 0.1132 - val_accuracy: 0.9841 - val_loss: 0.0502 - learning_rate: 0.0010\n",
      "Epoch 26/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 14ms/step - accuracy: 0.9654 - loss: 0.1091 - val_accuracy: 0.9853 - val_loss: 0.0489 - learning_rate: 0.0010\n",
      "Epoch 27/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9654 - loss: 0.1105 - val_accuracy: 0.9854 - val_loss: 0.0497 - learning_rate: 0.0010\n",
      "Epoch 28/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9662 - loss: 0.1083 - val_accuracy: 0.9848 - val_loss: 0.0481 - learning_rate: 0.0010\n",
      "Epoch 29/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9725 - loss: 0.0854 - val_accuracy: 0.9898 - val_loss: 0.0342 - learning_rate: 5.0000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9777 - loss: 0.0705 - val_accuracy: 0.9899 - val_loss: 0.0324 - learning_rate: 5.0000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9786 - loss: 0.0680 - val_accuracy: 0.9902 - val_loss: 0.0323 - learning_rate: 5.0000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 14ms/step - accuracy: 0.9782 - loss: 0.0681 - val_accuracy: 0.9886 - val_loss: 0.0360 - learning_rate: 5.0000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9782 - loss: 0.0680 - val_accuracy: 0.9888 - val_loss: 0.0353 - learning_rate: 5.0000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9800 - loss: 0.0640 - val_accuracy: 0.9903 - val_loss: 0.0340 - learning_rate: 5.0000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 14ms/step - accuracy: 0.9797 - loss: 0.0637 - val_accuracy: 0.9896 - val_loss: 0.0366 - learning_rate: 5.0000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9825 - loss: 0.0544 - val_accuracy: 0.9921 - val_loss: 0.0273 - learning_rate: 2.5000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 14ms/step - accuracy: 0.9844 - loss: 0.0475 - val_accuracy: 0.9913 - val_loss: 0.0284 - learning_rate: 2.5000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 14ms/step - accuracy: 0.9858 - loss: 0.0459 - val_accuracy: 0.9913 - val_loss: 0.0296 - learning_rate: 2.5000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9852 - loss: 0.0448 - val_accuracy: 0.9912 - val_loss: 0.0287 - learning_rate: 2.5000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9854 - loss: 0.0460 - val_accuracy: 0.9911 - val_loss: 0.0299 - learning_rate: 2.5000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 14ms/step - accuracy: 0.9858 - loss: 0.0436 - val_accuracy: 0.9913 - val_loss: 0.0282 - learning_rate: 2.5000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9875 - loss: 0.0397 - val_accuracy: 0.9925 - val_loss: 0.0260 - learning_rate: 1.2500e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9882 - loss: 0.0368 - val_accuracy: 0.9922 - val_loss: 0.0269 - learning_rate: 1.2500e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9877 - loss: 0.0384 - val_accuracy: 0.9925 - val_loss: 0.0266 - learning_rate: 1.2500e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 14ms/step - accuracy: 0.9890 - loss: 0.0347 - val_accuracy: 0.9921 - val_loss: 0.0261 - learning_rate: 1.2500e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 14ms/step - accuracy: 0.9889 - loss: 0.0355 - val_accuracy: 0.9923 - val_loss: 0.0269 - learning_rate: 1.2500e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9884 - loss: 0.0341 - val_accuracy: 0.9922 - val_loss: 0.0261 - learning_rate: 1.2500e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9887 - loss: 0.0333 - val_accuracy: 0.9924 - val_loss: 0.0261 - learning_rate: 6.2500e-05\n",
      "Epoch 49/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9904 - loss: 0.0307 - val_accuracy: 0.9926 - val_loss: 0.0254 - learning_rate: 6.2500e-05\n",
      "Epoch 50/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 14ms/step - accuracy: 0.9900 - loss: 0.0304 - val_accuracy: 0.9923 - val_loss: 0.0251 - learning_rate: 6.2500e-05\n",
      "Epoch 51/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 13ms/step - accuracy: 0.9895 - loss: 0.0318 - val_accuracy: 0.9929 - val_loss: 0.0258 - learning_rate: 6.2500e-05\n",
      "Epoch 52/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9907 - loss: 0.0285 - val_accuracy: 0.9928 - val_loss: 0.0255 - learning_rate: 6.2500e-05\n",
      "Epoch 53/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9900 - loss: 0.0304 - val_accuracy: 0.9929 - val_loss: 0.0257 - learning_rate: 6.2500e-05\n",
      "Epoch 54/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9891 - loss: 0.0316 - val_accuracy: 0.9926 - val_loss: 0.0253 - learning_rate: 6.2500e-05\n",
      "Epoch 55/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 14ms/step - accuracy: 0.9899 - loss: 0.0301 - val_accuracy: 0.9925 - val_loss: 0.0258 - learning_rate: 6.2500e-05\n",
      "Epoch 56/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9908 - loss: 0.0293 - val_accuracy: 0.9926 - val_loss: 0.0255 - learning_rate: 3.1250e-05\n",
      "Epoch 57/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9910 - loss: 0.0282 - val_accuracy: 0.9928 - val_loss: 0.0253 - learning_rate: 3.1250e-05\n",
      "Epoch 58/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9909 - loss: 0.0277 - val_accuracy: 0.9926 - val_loss: 0.0251 - learning_rate: 3.1250e-05\n",
      "Epoch 59/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 13ms/step - accuracy: 0.9903 - loss: 0.0303 - val_accuracy: 0.9930 - val_loss: 0.0251 - learning_rate: 3.1250e-05\n",
      "Epoch 60/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9911 - loss: 0.0279 - val_accuracy: 0.9931 - val_loss: 0.0253 - learning_rate: 3.1250e-05\n",
      "Epoch 61/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9912 - loss: 0.0271 - val_accuracy: 0.9930 - val_loss: 0.0254 - learning_rate: 1.5625e-05\n",
      "Epoch 62/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9908 - loss: 0.0273 - val_accuracy: 0.9928 - val_loss: 0.0256 - learning_rate: 1.5625e-05\n",
      "Epoch 63/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 14ms/step - accuracy: 0.9908 - loss: 0.0280 - val_accuracy: 0.9929 - val_loss: 0.0254 - learning_rate: 1.5625e-05\n",
      "Epoch 64/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9915 - loss: 0.0262 - val_accuracy: 0.9929 - val_loss: 0.0257 - learning_rate: 1.5625e-05\n",
      "Epoch 65/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9912 - loss: 0.0258 - val_accuracy: 0.9928 - val_loss: 0.0254 - learning_rate: 1.5625e-05\n",
      "Epoch 66/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9904 - loss: 0.0285 - val_accuracy: 0.9931 - val_loss: 0.0252 - learning_rate: 7.8125e-06\n",
      "Epoch 67/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 13ms/step - accuracy: 0.9917 - loss: 0.0257 - val_accuracy: 0.9931 - val_loss: 0.0249 - learning_rate: 7.8125e-06\n",
      "Epoch 68/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 14ms/step - accuracy: 0.9913 - loss: 0.0263 - val_accuracy: 0.9929 - val_loss: 0.0251 - learning_rate: 7.8125e-06\n",
      "Epoch 69/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9915 - loss: 0.0259 - val_accuracy: 0.9930 - val_loss: 0.0251 - learning_rate: 7.8125e-06\n",
      "Epoch 70/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 14ms/step - accuracy: 0.9911 - loss: 0.0266 - val_accuracy: 0.9929 - val_loss: 0.0252 - learning_rate: 7.8125e-06\n",
      "Epoch 71/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 13ms/step - accuracy: 0.9910 - loss: 0.0265 - val_accuracy: 0.9931 - val_loss: 0.0248 - learning_rate: 7.8125e-06\n",
      "Epoch 72/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 14ms/step - accuracy: 0.9917 - loss: 0.0259 - val_accuracy: 0.9931 - val_loss: 0.0248 - learning_rate: 7.8125e-06\n",
      "Epoch 73/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9911 - loss: 0.0266 - val_accuracy: 0.9932 - val_loss: 0.0246 - learning_rate: 7.8125e-06\n",
      "Epoch 74/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9913 - loss: 0.0256 - val_accuracy: 0.9929 - val_loss: 0.0250 - learning_rate: 7.8125e-06\n",
      "Epoch 75/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 13ms/step - accuracy: 0.9919 - loss: 0.0249 - val_accuracy: 0.9930 - val_loss: 0.0251 - learning_rate: 7.8125e-06\n",
      "Epoch 76/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9922 - loss: 0.0248 - val_accuracy: 0.9931 - val_loss: 0.0249 - learning_rate: 7.8125e-06\n",
      "Epoch 77/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 14ms/step - accuracy: 0.9916 - loss: 0.0252 - val_accuracy: 0.9930 - val_loss: 0.0247 - learning_rate: 7.8125e-06\n",
      "Epoch 78/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9914 - loss: 0.0253 - val_accuracy: 0.9932 - val_loss: 0.0248 - learning_rate: 7.8125e-06\n",
      "Epoch 79/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 13ms/step - accuracy: 0.9906 - loss: 0.0283 - val_accuracy: 0.9929 - val_loss: 0.0249 - learning_rate: 3.9063e-06\n",
      "Epoch 80/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 14ms/step - accuracy: 0.9910 - loss: 0.0276 - val_accuracy: 0.9932 - val_loss: 0.0247 - learning_rate: 3.9063e-06\n",
      "Epoch 81/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 14ms/step - accuracy: 0.9912 - loss: 0.0266 - val_accuracy: 0.9931 - val_loss: 0.0248 - learning_rate: 3.9063e-06\n",
      "Epoch 82/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 14ms/step - accuracy: 0.9920 - loss: 0.0240 - val_accuracy: 0.9930 - val_loss: 0.0246 - learning_rate: 3.9063e-06\n",
      "Epoch 83/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 13ms/step - accuracy: 0.9907 - loss: 0.0286 - val_accuracy: 0.9930 - val_loss: 0.0248 - learning_rate: 3.9063e-06\n"
     ]
    }
   ],
   "source": [
    "time_callback = TimeHistory()\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "\n",
    "model.add(GRU(64, input_shape=(32, 120), return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(GRU(32, return_sequences=False))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))  \n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Dense(128, activation='linear', name = 'bottleneck'))\n",
    "\n",
    "\n",
    "model.add(Dense(100, activation='softmax'))  \n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-8)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,    \n",
    "    y_train,    \n",
    "    epochs=200,  \n",
    "    batch_size=32, \n",
    "    verbose = 1,\n",
    "    validation_data=(X_valid, y_valid),  \n",
    "    callbacks=[reduce_lr, early_stopping, time_callback]  \n",
    ")\n",
    "\n",
    "GRU_time = sum(time_callback.times[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73bfe57e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T15:15:26.077183Z",
     "iopub.status.busy": "2024-11-20T15:15:26.076844Z",
     "iopub.status.idle": "2024-11-20T15:15:26.159071Z",
     "shell.execute_reply": "2024-11-20T15:15:26.158125Z"
    },
    "papermill": {
     "duration": 7.113864,
     "end_time": "2024-11-20T15:15:26.161232",
     "exception": false,
     "start_time": "2024-11-20T15:15:19.047368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('model_GRU.h5')\n",
    "np.save('GRU_time.npy', GRU_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3800199",
   "metadata": {},
   "source": [
    "# Klasyczna RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c0f2f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T15:15:40.202927Z",
     "iopub.status.busy": "2024-11-20T15:15:40.202050Z",
     "iopub.status.idle": "2024-11-20T17:01:32.987288Z",
     "shell.execute_reply": "2024-11-20T17:01:32.986312Z"
    },
    "papermill": {
     "duration": 6359.745161,
     "end_time": "2024-11-20T17:01:32.989543",
     "exception": false,
     "start_time": "2024-11-20T15:15:33.244382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,840</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,104</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bottleneck (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,900</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m11,840\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_1 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m3,104\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │        \u001b[38;5;34m33,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │         \u001b[38;5;34m4,096\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m524,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bottleneck (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m12,900\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">758,212</span> (2.89 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m758,212\u001b[0m (2.89 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">754,436</span> (2.88 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m754,436\u001b[0m (2.88 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,776</span> (14.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,776\u001b[0m (14.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732115749.829691      64 service.cc:145] XLA service 0x5cdef92da500 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1732115749.829754      64 service.cc:153]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  22/3775\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 8ms/step - accuracy: 0.0090 - loss: 5.5244"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1732115758.700762      64 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.1039 - loss: 3.9252Czas dla epoki 1: 53.97 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 11ms/step - accuracy: 0.1039 - loss: 3.9251 - val_accuracy: 0.2446 - val_loss: 2.9358 - learning_rate: 0.0010\n",
      "Epoch 2/200\n",
      "\u001b[1m3769/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2292 - loss: 2.9865Czas dla epoki 2: 31.93 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.2292 - loss: 2.9865 - val_accuracy: 0.2811 - val_loss: 2.6960 - learning_rate: 0.0010\n",
      "Epoch 3/200\n",
      "\u001b[1m3769/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2376 - loss: 2.9466Czas dla epoki 3: 31.52 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.2376 - loss: 2.9467 - val_accuracy: 0.2718 - val_loss: 2.7486 - learning_rate: 0.0010\n",
      "Epoch 4/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2211 - loss: 3.0219Czas dla epoki 4: 32.18 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 9ms/step - accuracy: 0.2211 - loss: 3.0219 - val_accuracy: 0.2867 - val_loss: 2.6720 - learning_rate: 0.0010\n",
      "Epoch 5/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2550 - loss: 2.8462Czas dla epoki 5: 31.62 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.2550 - loss: 2.8462 - val_accuracy: 0.2739 - val_loss: 2.7556 - learning_rate: 0.0010\n",
      "Epoch 6/200\n",
      "\u001b[1m3774/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2330 - loss: 2.9607Czas dla epoki 6: 31.92 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.2330 - loss: 2.9607 - val_accuracy: 0.2472 - val_loss: 2.9004 - learning_rate: 0.0010\n",
      "Epoch 7/200\n",
      "\u001b[1m3772/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2098 - loss: 3.0956Czas dla epoki 7: 31.63 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.2098 - loss: 3.0956 - val_accuracy: 0.2762 - val_loss: 2.6905 - learning_rate: 0.0010\n",
      "Epoch 8/200\n",
      "\u001b[1m3772/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2267 - loss: 2.9828Czas dla epoki 8: 32.06 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.2267 - loss: 2.9828 - val_accuracy: 0.2369 - val_loss: 2.8793 - learning_rate: 0.0010\n",
      "Epoch 9/200\n",
      "\u001b[1m3773/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1926 - loss: 3.1584Czas dla epoki 9: 31.54 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.1926 - loss: 3.1584 - val_accuracy: 0.2418 - val_loss: 2.8479 - learning_rate: 0.0010\n",
      "Epoch 10/200\n",
      "\u001b[1m3773/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2138 - loss: 3.0173Czas dla epoki 10: 32.15 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 9ms/step - accuracy: 0.2138 - loss: 3.0172 - val_accuracy: 0.2778 - val_loss: 2.6905 - learning_rate: 5.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m3769/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2331 - loss: 2.9308Czas dla epoki 11: 31.52 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.2331 - loss: 2.9307 - val_accuracy: 0.2892 - val_loss: 2.6103 - learning_rate: 5.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m3770/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2526 - loss: 2.8516Czas dla epoki 12: 32.25 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 9ms/step - accuracy: 0.2526 - loss: 2.8516 - val_accuracy: 0.2867 - val_loss: 2.6689 - learning_rate: 5.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2430 - loss: 2.8924Czas dla epoki 13: 32.52 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 9ms/step - accuracy: 0.2430 - loss: 2.8924 - val_accuracy: 0.2849 - val_loss: 2.6604 - learning_rate: 5.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m3772/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2494 - loss: 2.8670Czas dla epoki 14: 32.40 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 9ms/step - accuracy: 0.2494 - loss: 2.8670 - val_accuracy: 0.3015 - val_loss: 2.6228 - learning_rate: 5.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m3770/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2470 - loss: 2.8675Czas dla epoki 15: 32.82 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 9ms/step - accuracy: 0.2470 - loss: 2.8675 - val_accuracy: 0.2918 - val_loss: 2.6439 - learning_rate: 5.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2498 - loss: 2.8509Czas dla epoki 16: 32.32 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 9ms/step - accuracy: 0.2498 - loss: 2.8509 - val_accuracy: 0.3038 - val_loss: 2.5692 - learning_rate: 5.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m3772/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2590 - loss: 2.7996Czas dla epoki 17: 32.78 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 9ms/step - accuracy: 0.2590 - loss: 2.7996 - val_accuracy: 0.2944 - val_loss: 2.6211 - learning_rate: 5.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m3773/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2506 - loss: 2.8252Czas dla epoki 18: 32.28 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 9ms/step - accuracy: 0.2506 - loss: 2.8252 - val_accuracy: 0.2819 - val_loss: 2.6790 - learning_rate: 5.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m3773/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2413 - loss: 2.9046Czas dla epoki 19: 32.92 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 9ms/step - accuracy: 0.2413 - loss: 2.9046 - val_accuracy: 0.3011 - val_loss: 2.5835 - learning_rate: 5.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m3772/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2496 - loss: 2.8521Czas dla epoki 20: 32.41 sekundy\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 9ms/step - accuracy: 0.2496 - loss: 2.8521 - val_accuracy: 0.2940 - val_loss: 2.6107 - learning_rate: 5.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.2474 - loss: 2.8662 - val_accuracy: 0.2922 - val_loss: 2.6201 - learning_rate: 5.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.2560 - loss: 2.8271 - val_accuracy: 0.3118 - val_loss: 2.5410 - learning_rate: 2.5000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 9ms/step - accuracy: 0.2657 - loss: 2.7694 - val_accuracy: 0.3120 - val_loss: 2.5173 - learning_rate: 2.5000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.2681 - loss: 2.7614 - val_accuracy: 0.3215 - val_loss: 2.4697 - learning_rate: 2.5000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.2782 - loss: 2.7122 - val_accuracy: 0.3186 - val_loss: 2.4742 - learning_rate: 2.5000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.2764 - loss: 2.6976 - val_accuracy: 0.3321 - val_loss: 2.4205 - learning_rate: 2.5000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.2812 - loss: 2.6732 - val_accuracy: 0.3334 - val_loss: 2.4156 - learning_rate: 2.5000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 9ms/step - accuracy: 0.2853 - loss: 2.6586 - val_accuracy: 0.3403 - val_loss: 2.3971 - learning_rate: 2.5000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.2927 - loss: 2.6302 - val_accuracy: 0.3448 - val_loss: 2.3776 - learning_rate: 2.5000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 9ms/step - accuracy: 0.2939 - loss: 2.6317 - val_accuracy: 0.3422 - val_loss: 2.3880 - learning_rate: 2.5000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.2925 - loss: 2.6406 - val_accuracy: 0.3490 - val_loss: 2.3607 - learning_rate: 2.5000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 9ms/step - accuracy: 0.2992 - loss: 2.6213 - val_accuracy: 0.3455 - val_loss: 2.3762 - learning_rate: 2.5000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.2959 - loss: 2.6285 - val_accuracy: 0.3504 - val_loss: 2.3680 - learning_rate: 2.5000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.2954 - loss: 2.6343 - val_accuracy: 0.3461 - val_loss: 2.3683 - learning_rate: 2.5000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.2899 - loss: 2.6409 - val_accuracy: 0.3437 - val_loss: 2.3973 - learning_rate: 2.5000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 9ms/step - accuracy: 0.2853 - loss: 2.6702 - val_accuracy: 0.3424 - val_loss: 2.3900 - learning_rate: 2.5000e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 9ms/step - accuracy: 0.2950 - loss: 2.6278 - val_accuracy: 0.3523 - val_loss: 2.3401 - learning_rate: 1.2500e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.2996 - loss: 2.5900 - val_accuracy: 0.3570 - val_loss: 2.3172 - learning_rate: 1.2500e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.3036 - loss: 2.5752 - val_accuracy: 0.3610 - val_loss: 2.3060 - learning_rate: 1.2500e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.3027 - loss: 2.5797 - val_accuracy: 0.3628 - val_loss: 2.3063 - learning_rate: 1.2500e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 9ms/step - accuracy: 0.3079 - loss: 2.5602 - val_accuracy: 0.3631 - val_loss: 2.2970 - learning_rate: 1.2500e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 9ms/step - accuracy: 0.3102 - loss: 2.5496 - val_accuracy: 0.3693 - val_loss: 2.2801 - learning_rate: 1.2500e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 9ms/step - accuracy: 0.3095 - loss: 2.5522 - val_accuracy: 0.3655 - val_loss: 2.2964 - learning_rate: 1.2500e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.3089 - loss: 2.5578 - val_accuracy: 0.3679 - val_loss: 2.2776 - learning_rate: 1.2500e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 9ms/step - accuracy: 0.3137 - loss: 2.5323 - val_accuracy: 0.3713 - val_loss: 2.2735 - learning_rate: 1.2500e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.3134 - loss: 2.5480 - val_accuracy: 0.3652 - val_loss: 2.2812 - learning_rate: 1.2500e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.3132 - loss: 2.5414 - val_accuracy: 0.3622 - val_loss: 2.3082 - learning_rate: 1.2500e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.3079 - loss: 2.5624 - val_accuracy: 0.3624 - val_loss: 2.2985 - learning_rate: 1.2500e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.3114 - loss: 2.5497 - val_accuracy: 0.3634 - val_loss: 2.2871 - learning_rate: 1.2500e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 9ms/step - accuracy: 0.3171 - loss: 2.5360 - val_accuracy: 0.3703 - val_loss: 2.2650 - learning_rate: 1.2500e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.3167 - loss: 2.5182 - val_accuracy: 0.3747 - val_loss: 2.2460 - learning_rate: 1.2500e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 9ms/step - accuracy: 0.3150 - loss: 2.5190 - val_accuracy: 0.3724 - val_loss: 2.2628 - learning_rate: 1.2500e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.3191 - loss: 2.5078 - val_accuracy: 0.3746 - val_loss: 2.2540 - learning_rate: 1.2500e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 9ms/step - accuracy: 0.3191 - loss: 2.5157 - val_accuracy: 0.3721 - val_loss: 2.2659 - learning_rate: 1.2500e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.3178 - loss: 2.5198 - val_accuracy: 0.3787 - val_loss: 2.2352 - learning_rate: 1.2500e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 9ms/step - accuracy: 0.3257 - loss: 2.4907 - val_accuracy: 0.3767 - val_loss: 2.2375 - learning_rate: 1.2500e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.3223 - loss: 2.5049 - val_accuracy: 0.3759 - val_loss: 2.2427 - learning_rate: 1.2500e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 9ms/step - accuracy: 0.3210 - loss: 2.5025 - val_accuracy: 0.3794 - val_loss: 2.2295 - learning_rate: 1.2500e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 9ms/step - accuracy: 0.3237 - loss: 2.4999 - val_accuracy: 0.3809 - val_loss: 2.2311 - learning_rate: 1.2500e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.3260 - loss: 2.4859 - val_accuracy: 0.3817 - val_loss: 2.2181 - learning_rate: 1.2500e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 9ms/step - accuracy: 0.3269 - loss: 2.4823 - val_accuracy: 0.3814 - val_loss: 2.2193 - learning_rate: 1.2500e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.3265 - loss: 2.4680 - val_accuracy: 0.3855 - val_loss: 2.2093 - learning_rate: 1.2500e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 9ms/step - accuracy: 0.3249 - loss: 2.4793 - val_accuracy: 0.3809 - val_loss: 2.2265 - learning_rate: 1.2500e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.3226 - loss: 2.4984 - val_accuracy: 0.3813 - val_loss: 2.2208 - learning_rate: 1.2500e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 9ms/step - accuracy: 0.3258 - loss: 2.4789 - val_accuracy: 0.3834 - val_loss: 2.2125 - learning_rate: 1.2500e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.3280 - loss: 2.4680 - val_accuracy: 0.3772 - val_loss: 2.2199 - learning_rate: 1.2500e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 9ms/step - accuracy: 0.3263 - loss: 2.4704 - val_accuracy: 0.3809 - val_loss: 2.2183 - learning_rate: 1.2500e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.3307 - loss: 2.4627 - val_accuracy: 0.3816 - val_loss: 2.2066 - learning_rate: 6.2500e-05\n",
      "Epoch 69/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.3269 - loss: 2.4637 - val_accuracy: 0.3795 - val_loss: 2.2083 - learning_rate: 6.2500e-05\n",
      "Epoch 70/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 9ms/step - accuracy: 0.3295 - loss: 2.4604 - val_accuracy: 0.3791 - val_loss: 2.2051 - learning_rate: 6.2500e-05\n",
      "Epoch 71/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.3304 - loss: 2.4558 - val_accuracy: 0.3825 - val_loss: 2.1997 - learning_rate: 6.2500e-05\n",
      "Epoch 72/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 9ms/step - accuracy: 0.3352 - loss: 2.4403 - val_accuracy: 0.3819 - val_loss: 2.1934 - learning_rate: 6.2500e-05\n",
      "Epoch 73/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.3331 - loss: 2.4460 - val_accuracy: 0.3840 - val_loss: 2.1822 - learning_rate: 6.2500e-05\n",
      "Epoch 74/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 9ms/step - accuracy: 0.3370 - loss: 2.4233 - val_accuracy: 0.3862 - val_loss: 2.1848 - learning_rate: 6.2500e-05\n",
      "Epoch 75/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.3350 - loss: 2.4360 - val_accuracy: 0.3858 - val_loss: 2.1863 - learning_rate: 6.2500e-05\n",
      "Epoch 76/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 9ms/step - accuracy: 0.3350 - loss: 2.4351 - val_accuracy: 0.3881 - val_loss: 2.1757 - learning_rate: 6.2500e-05\n",
      "Epoch 77/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.3376 - loss: 2.4227 - val_accuracy: 0.3897 - val_loss: 2.1694 - learning_rate: 6.2500e-05\n",
      "Epoch 78/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.3382 - loss: 2.4190 - val_accuracy: 0.3887 - val_loss: 2.1705 - learning_rate: 6.2500e-05\n",
      "Epoch 79/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 9ms/step - accuracy: 0.3365 - loss: 2.4218 - val_accuracy: 0.3904 - val_loss: 2.1636 - learning_rate: 6.2500e-05\n",
      "Epoch 80/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.3392 - loss: 2.4170 - val_accuracy: 0.3911 - val_loss: 2.1647 - learning_rate: 6.2500e-05\n",
      "Epoch 81/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 9ms/step - accuracy: 0.3416 - loss: 2.4064 - val_accuracy: 0.3944 - val_loss: 2.1546 - learning_rate: 6.2500e-05\n",
      "Epoch 82/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.3390 - loss: 2.4185 - val_accuracy: 0.3958 - val_loss: 2.1547 - learning_rate: 6.2500e-05\n",
      "Epoch 83/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 9ms/step - accuracy: 0.3364 - loss: 2.4227 - val_accuracy: 0.3964 - val_loss: 2.1535 - learning_rate: 6.2500e-05\n",
      "Epoch 84/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.3359 - loss: 2.4203 - val_accuracy: 0.3973 - val_loss: 2.1504 - learning_rate: 6.2500e-05\n",
      "Epoch 85/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 9ms/step - accuracy: 0.3414 - loss: 2.4004 - val_accuracy: 0.3977 - val_loss: 2.1488 - learning_rate: 6.2500e-05\n",
      "Epoch 86/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.3422 - loss: 2.4104 - val_accuracy: 0.4017 - val_loss: 2.1430 - learning_rate: 6.2500e-05\n",
      "Epoch 87/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 9ms/step - accuracy: 0.3441 - loss: 2.3989 - val_accuracy: 0.4000 - val_loss: 2.1384 - learning_rate: 6.2500e-05\n",
      "Epoch 88/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 9ms/step - accuracy: 0.3445 - loss: 2.3979 - val_accuracy: 0.4015 - val_loss: 2.1343 - learning_rate: 6.2500e-05\n",
      "Epoch 89/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.3423 - loss: 2.4067 - val_accuracy: 0.4027 - val_loss: 2.1391 - learning_rate: 6.2500e-05\n",
      "Epoch 90/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 9ms/step - accuracy: 0.3443 - loss: 2.3940 - val_accuracy: 0.4008 - val_loss: 2.1414 - learning_rate: 6.2500e-05\n",
      "Epoch 91/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.3464 - loss: 2.3993 - val_accuracy: 0.4054 - val_loss: 2.1246 - learning_rate: 6.2500e-05\n",
      "Epoch 92/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 9ms/step - accuracy: 0.3460 - loss: 2.3968 - val_accuracy: 0.4031 - val_loss: 2.1275 - learning_rate: 6.2500e-05\n",
      "Epoch 93/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.3463 - loss: 2.3889 - val_accuracy: 0.4024 - val_loss: 2.1306 - learning_rate: 6.2500e-05\n",
      "Epoch 94/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 9ms/step - accuracy: 0.3455 - loss: 2.3929 - val_accuracy: 0.4022 - val_loss: 2.1366 - learning_rate: 6.2500e-05\n",
      "Epoch 95/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.3432 - loss: 2.3947 - val_accuracy: 0.3996 - val_loss: 2.1348 - learning_rate: 6.2500e-05\n",
      "Epoch 96/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.3473 - loss: 2.3868 - val_accuracy: 0.4005 - val_loss: 2.1291 - learning_rate: 6.2500e-05\n",
      "Epoch 97/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 9ms/step - accuracy: 0.3440 - loss: 2.3888 - val_accuracy: 0.4043 - val_loss: 2.1246 - learning_rate: 3.1250e-05\n",
      "Epoch 98/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.3460 - loss: 2.3841 - val_accuracy: 0.4049 - val_loss: 2.1220 - learning_rate: 3.1250e-05\n",
      "Epoch 99/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 9ms/step - accuracy: 0.3461 - loss: 2.3891 - val_accuracy: 0.4060 - val_loss: 2.1181 - learning_rate: 3.1250e-05\n",
      "Epoch 100/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.3472 - loss: 2.3715 - val_accuracy: 0.4041 - val_loss: 2.1135 - learning_rate: 3.1250e-05\n",
      "Epoch 101/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 9ms/step - accuracy: 0.3470 - loss: 2.3780 - val_accuracy: 0.4040 - val_loss: 2.1109 - learning_rate: 3.1250e-05\n",
      "Epoch 102/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.3498 - loss: 2.3723 - val_accuracy: 0.4084 - val_loss: 2.1081 - learning_rate: 3.1250e-05\n",
      "Epoch 103/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 9ms/step - accuracy: 0.3466 - loss: 2.3761 - val_accuracy: 0.4069 - val_loss: 2.1085 - learning_rate: 3.1250e-05\n",
      "Epoch 104/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.3499 - loss: 2.3668 - val_accuracy: 0.4072 - val_loss: 2.1047 - learning_rate: 3.1250e-05\n",
      "Epoch 105/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.3487 - loss: 2.3565 - val_accuracy: 0.4068 - val_loss: 2.1021 - learning_rate: 3.1250e-05\n",
      "Epoch 106/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 9ms/step - accuracy: 0.3519 - loss: 2.3567 - val_accuracy: 0.4090 - val_loss: 2.1057 - learning_rate: 3.1250e-05\n",
      "Epoch 107/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.3534 - loss: 2.3673 - val_accuracy: 0.4094 - val_loss: 2.1020 - learning_rate: 3.1250e-05\n",
      "Epoch 108/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 9ms/step - accuracy: 0.3512 - loss: 2.3653 - val_accuracy: 0.4100 - val_loss: 2.1016 - learning_rate: 3.1250e-05\n",
      "Epoch 109/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.3520 - loss: 2.3534 - val_accuracy: 0.4092 - val_loss: 2.1005 - learning_rate: 3.1250e-05\n",
      "Epoch 110/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 9ms/step - accuracy: 0.3518 - loss: 2.3584 - val_accuracy: 0.4089 - val_loss: 2.0995 - learning_rate: 3.1250e-05\n",
      "Epoch 111/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.3545 - loss: 2.3513 - val_accuracy: 0.4091 - val_loss: 2.0986 - learning_rate: 3.1250e-05\n",
      "Epoch 112/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 9ms/step - accuracy: 0.3531 - loss: 2.3503 - val_accuracy: 0.4090 - val_loss: 2.0959 - learning_rate: 3.1250e-05\n",
      "Epoch 113/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 9ms/step - accuracy: 0.3519 - loss: 2.3600 - val_accuracy: 0.4095 - val_loss: 2.0956 - learning_rate: 3.1250e-05\n",
      "Epoch 114/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.3566 - loss: 2.3491 - val_accuracy: 0.4089 - val_loss: 2.0984 - learning_rate: 3.1250e-05\n",
      "Epoch 115/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 9ms/step - accuracy: 0.3490 - loss: 2.3697 - val_accuracy: 0.4085 - val_loss: 2.1009 - learning_rate: 3.1250e-05\n",
      "Epoch 116/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.3562 - loss: 2.3451 - val_accuracy: 0.4134 - val_loss: 2.0900 - learning_rate: 3.1250e-05\n",
      "Epoch 117/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 9ms/step - accuracy: 0.3571 - loss: 2.3471 - val_accuracy: 0.4124 - val_loss: 2.0892 - learning_rate: 3.1250e-05\n",
      "Epoch 118/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.3532 - loss: 2.3519 - val_accuracy: 0.4152 - val_loss: 2.0809 - learning_rate: 3.1250e-05\n",
      "Epoch 119/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 9ms/step - accuracy: 0.3545 - loss: 2.3444 - val_accuracy: 0.4139 - val_loss: 2.0830 - learning_rate: 3.1250e-05\n",
      "Epoch 120/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.3569 - loss: 2.3444 - val_accuracy: 0.4123 - val_loss: 2.0844 - learning_rate: 3.1250e-05\n",
      "Epoch 121/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.3572 - loss: 2.3393 - val_accuracy: 0.4131 - val_loss: 2.0812 - learning_rate: 3.1250e-05\n",
      "Epoch 122/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 9ms/step - accuracy: 0.3527 - loss: 2.3459 - val_accuracy: 0.4115 - val_loss: 2.0840 - learning_rate: 3.1250e-05\n",
      "Epoch 123/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 9ms/step - accuracy: 0.3546 - loss: 2.3435 - val_accuracy: 0.4145 - val_loss: 2.0803 - learning_rate: 3.1250e-05\n",
      "Epoch 124/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 9ms/step - accuracy: 0.3548 - loss: 2.3419 - val_accuracy: 0.4145 - val_loss: 2.0793 - learning_rate: 3.1250e-05\n",
      "Epoch 125/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 9ms/step - accuracy: 0.3581 - loss: 2.3320 - val_accuracy: 0.4124 - val_loss: 2.0795 - learning_rate: 3.1250e-05\n",
      "Epoch 126/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 9ms/step - accuracy: 0.3611 - loss: 2.3270 - val_accuracy: 0.4145 - val_loss: 2.0773 - learning_rate: 3.1250e-05\n",
      "Epoch 127/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.3559 - loss: 2.3388 - val_accuracy: 0.4142 - val_loss: 2.0781 - learning_rate: 3.1250e-05\n",
      "Epoch 128/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 9ms/step - accuracy: 0.3585 - loss: 2.3390 - val_accuracy: 0.4160 - val_loss: 2.0765 - learning_rate: 3.1250e-05\n",
      "Epoch 129/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 9ms/step - accuracy: 0.3565 - loss: 2.3420 - val_accuracy: 0.4163 - val_loss: 2.0731 - learning_rate: 3.1250e-05\n",
      "Epoch 130/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.3589 - loss: 2.3385 - val_accuracy: 0.4146 - val_loss: 2.0768 - learning_rate: 3.1250e-05\n",
      "Epoch 131/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.3606 - loss: 2.3230 - val_accuracy: 0.4164 - val_loss: 2.0740 - learning_rate: 3.1250e-05\n",
      "Epoch 132/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.3589 - loss: 2.3332 - val_accuracy: 0.4159 - val_loss: 2.0708 - learning_rate: 3.1250e-05\n",
      "Epoch 133/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.3588 - loss: 2.3389 - val_accuracy: 0.4155 - val_loss: 2.0768 - learning_rate: 3.1250e-05\n",
      "Epoch 134/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.3563 - loss: 2.3420 - val_accuracy: 0.4154 - val_loss: 2.0738 - learning_rate: 3.1250e-05\n",
      "Epoch 135/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.3576 - loss: 2.3409 - val_accuracy: 0.4143 - val_loss: 2.0706 - learning_rate: 3.1250e-05\n",
      "Epoch 136/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.3599 - loss: 2.3302 - val_accuracy: 0.4168 - val_loss: 2.0700 - learning_rate: 3.1250e-05\n",
      "Epoch 137/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.3604 - loss: 2.3221 - val_accuracy: 0.4171 - val_loss: 2.0714 - learning_rate: 3.1250e-05\n",
      "Epoch 138/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.3570 - loss: 2.3401 - val_accuracy: 0.4178 - val_loss: 2.0677 - learning_rate: 3.1250e-05\n",
      "Epoch 139/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.3611 - loss: 2.3252 - val_accuracy: 0.4173 - val_loss: 2.0683 - learning_rate: 3.1250e-05\n",
      "Epoch 140/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.3584 - loss: 2.3339 - val_accuracy: 0.4184 - val_loss: 2.0694 - learning_rate: 3.1250e-05\n",
      "Epoch 141/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.3614 - loss: 2.3219 - val_accuracy: 0.4179 - val_loss: 2.0712 - learning_rate: 3.1250e-05\n",
      "Epoch 142/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.3595 - loss: 2.3304 - val_accuracy: 0.4185 - val_loss: 2.0664 - learning_rate: 3.1250e-05\n",
      "Epoch 143/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.3593 - loss: 2.3274 - val_accuracy: 0.4197 - val_loss: 2.0618 - learning_rate: 3.1250e-05\n",
      "Epoch 144/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.3598 - loss: 2.3273 - val_accuracy: 0.4166 - val_loss: 2.0673 - learning_rate: 3.1250e-05\n",
      "Epoch 145/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.3613 - loss: 2.3276 - val_accuracy: 0.4191 - val_loss: 2.0644 - learning_rate: 3.1250e-05\n",
      "Epoch 146/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.3609 - loss: 2.3247 - val_accuracy: 0.4193 - val_loss: 2.0607 - learning_rate: 3.1250e-05\n",
      "Epoch 147/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.3597 - loss: 2.3204 - val_accuracy: 0.4192 - val_loss: 2.0647 - learning_rate: 3.1250e-05\n",
      "Epoch 148/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.3592 - loss: 2.3256 - val_accuracy: 0.4201 - val_loss: 2.0662 - learning_rate: 3.1250e-05\n",
      "Epoch 149/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.3580 - loss: 2.3308 - val_accuracy: 0.4196 - val_loss: 2.0609 - learning_rate: 3.1250e-05\n",
      "Epoch 150/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 8ms/step - accuracy: 0.3622 - loss: 2.3283 - val_accuracy: 0.4211 - val_loss: 2.0570 - learning_rate: 3.1250e-05\n",
      "Epoch 151/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.3616 - loss: 2.3154 - val_accuracy: 0.4238 - val_loss: 2.0548 - learning_rate: 3.1250e-05\n",
      "Epoch 152/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.3599 - loss: 2.3273 - val_accuracy: 0.4204 - val_loss: 2.0575 - learning_rate: 3.1250e-05\n",
      "Epoch 153/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.3585 - loss: 2.3325 - val_accuracy: 0.4213 - val_loss: 2.0509 - learning_rate: 3.1250e-05\n",
      "Epoch 154/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.3638 - loss: 2.3184 - val_accuracy: 0.4219 - val_loss: 2.0562 - learning_rate: 3.1250e-05\n",
      "Epoch 155/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.3657 - loss: 2.3088 - val_accuracy: 0.4211 - val_loss: 2.0587 - learning_rate: 3.1250e-05\n",
      "Epoch 156/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.3627 - loss: 2.3148 - val_accuracy: 0.4222 - val_loss: 2.0545 - learning_rate: 3.1250e-05\n",
      "Epoch 157/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.3631 - loss: 2.3169 - val_accuracy: 0.4245 - val_loss: 2.0496 - learning_rate: 3.1250e-05\n",
      "Epoch 158/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.3645 - loss: 2.3208 - val_accuracy: 0.4247 - val_loss: 2.0502 - learning_rate: 3.1250e-05\n",
      "Epoch 159/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.3625 - loss: 2.3189 - val_accuracy: 0.4244 - val_loss: 2.0488 - learning_rate: 3.1250e-05\n",
      "Epoch 160/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.3616 - loss: 2.3168 - val_accuracy: 0.4262 - val_loss: 2.0411 - learning_rate: 3.1250e-05\n",
      "Epoch 161/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.3652 - loss: 2.3046 - val_accuracy: 0.4260 - val_loss: 2.0403 - learning_rate: 3.1250e-05\n",
      "Epoch 162/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.3680 - loss: 2.3049 - val_accuracy: 0.4281 - val_loss: 2.0353 - learning_rate: 3.1250e-05\n",
      "Epoch 163/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.3664 - loss: 2.3032 - val_accuracy: 0.4276 - val_loss: 2.0363 - learning_rate: 3.1250e-05\n",
      "Epoch 164/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.3631 - loss: 2.3109 - val_accuracy: 0.4255 - val_loss: 2.0385 - learning_rate: 3.1250e-05\n",
      "Epoch 165/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.3651 - loss: 2.3083 - val_accuracy: 0.4258 - val_loss: 2.0385 - learning_rate: 3.1250e-05\n",
      "Epoch 166/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.3640 - loss: 2.3104 - val_accuracy: 0.4266 - val_loss: 2.0394 - learning_rate: 3.1250e-05\n",
      "Epoch 167/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.3690 - loss: 2.2935 - val_accuracy: 0.4286 - val_loss: 2.0339 - learning_rate: 3.1250e-05\n",
      "Epoch 168/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.3666 - loss: 2.3016 - val_accuracy: 0.4293 - val_loss: 2.0321 - learning_rate: 3.1250e-05\n",
      "Epoch 169/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.3684 - loss: 2.2984 - val_accuracy: 0.4288 - val_loss: 2.0306 - learning_rate: 3.1250e-05\n",
      "Epoch 170/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.3645 - loss: 2.3076 - val_accuracy: 0.4283 - val_loss: 2.0291 - learning_rate: 3.1250e-05\n",
      "Epoch 171/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.3625 - loss: 2.3039 - val_accuracy: 0.4275 - val_loss: 2.0327 - learning_rate: 3.1250e-05\n",
      "Epoch 172/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.3676 - loss: 2.3006 - val_accuracy: 0.4286 - val_loss: 2.0321 - learning_rate: 3.1250e-05\n",
      "Epoch 173/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.3669 - loss: 2.3023 - val_accuracy: 0.4296 - val_loss: 2.0265 - learning_rate: 3.1250e-05\n",
      "Epoch 174/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.3650 - loss: 2.3010 - val_accuracy: 0.4274 - val_loss: 2.0341 - learning_rate: 3.1250e-05\n",
      "Epoch 175/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.3674 - loss: 2.3003 - val_accuracy: 0.4298 - val_loss: 2.0310 - learning_rate: 3.1250e-05\n",
      "Epoch 176/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.3682 - loss: 2.3032 - val_accuracy: 0.4315 - val_loss: 2.0278 - learning_rate: 3.1250e-05\n",
      "Epoch 177/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.3661 - loss: 2.2982 - val_accuracy: 0.4322 - val_loss: 2.0262 - learning_rate: 3.1250e-05\n",
      "Epoch 178/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.3680 - loss: 2.3018 - val_accuracy: 0.4328 - val_loss: 2.0220 - learning_rate: 3.1250e-05\n",
      "Epoch 179/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.3706 - loss: 2.2867 - val_accuracy: 0.4311 - val_loss: 2.0212 - learning_rate: 3.1250e-05\n",
      "Epoch 180/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.3692 - loss: 2.2865 - val_accuracy: 0.4316 - val_loss: 2.0239 - learning_rate: 3.1250e-05\n",
      "Epoch 181/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.3696 - loss: 2.2942 - val_accuracy: 0.4308 - val_loss: 2.0228 - learning_rate: 3.1250e-05\n",
      "Epoch 182/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.3679 - loss: 2.2965 - val_accuracy: 0.4290 - val_loss: 2.0235 - learning_rate: 3.1250e-05\n",
      "Epoch 183/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.3649 - loss: 2.3038 - val_accuracy: 0.4313 - val_loss: 2.0245 - learning_rate: 3.1250e-05\n",
      "Epoch 184/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.3687 - loss: 2.2899 - val_accuracy: 0.4333 - val_loss: 2.0201 - learning_rate: 3.1250e-05\n",
      "Epoch 185/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.3693 - loss: 2.2866 - val_accuracy: 0.4321 - val_loss: 2.0233 - learning_rate: 3.1250e-05\n",
      "Epoch 186/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.3725 - loss: 2.2792 - val_accuracy: 0.4315 - val_loss: 2.0230 - learning_rate: 3.1250e-05\n",
      "Epoch 187/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.3671 - loss: 2.2891 - val_accuracy: 0.4321 - val_loss: 2.0221 - learning_rate: 3.1250e-05\n",
      "Epoch 188/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.3698 - loss: 2.2927 - val_accuracy: 0.4301 - val_loss: 2.0249 - learning_rate: 3.1250e-05\n",
      "Epoch 189/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.3654 - loss: 2.2870 - val_accuracy: 0.4285 - val_loss: 2.0237 - learning_rate: 3.1250e-05\n",
      "Epoch 190/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.3687 - loss: 2.2844 - val_accuracy: 0.4314 - val_loss: 2.0198 - learning_rate: 1.5625e-05\n",
      "Epoch 191/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.3698 - loss: 2.2933 - val_accuracy: 0.4308 - val_loss: 2.0166 - learning_rate: 1.5625e-05\n",
      "Epoch 192/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.3683 - loss: 2.2871 - val_accuracy: 0.4307 - val_loss: 2.0211 - learning_rate: 1.5625e-05\n",
      "Epoch 193/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.3689 - loss: 2.2898 - val_accuracy: 0.4304 - val_loss: 2.0189 - learning_rate: 1.5625e-05\n",
      "Epoch 194/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.3679 - loss: 2.2901 - val_accuracy: 0.4317 - val_loss: 2.0190 - learning_rate: 1.5625e-05\n",
      "Epoch 195/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.3685 - loss: 2.2844 - val_accuracy: 0.4302 - val_loss: 2.0202 - learning_rate: 1.5625e-05\n",
      "Epoch 196/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.3713 - loss: 2.2834 - val_accuracy: 0.4297 - val_loss: 2.0195 - learning_rate: 1.5625e-05\n",
      "Epoch 197/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.3705 - loss: 2.2853 - val_accuracy: 0.4321 - val_loss: 2.0174 - learning_rate: 7.8125e-06\n",
      "Epoch 198/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 8ms/step - accuracy: 0.3720 - loss: 2.2791 - val_accuracy: 0.4313 - val_loss: 2.0161 - learning_rate: 7.8125e-06\n",
      "Epoch 199/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.3687 - loss: 2.2885 - val_accuracy: 0.4314 - val_loss: 2.0177 - learning_rate: 7.8125e-06\n",
      "Epoch 200/200\n",
      "\u001b[1m3775/3775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.3722 - loss: 2.2867 - val_accuracy: 0.4300 - val_loss: 2.0141 - learning_rate: 7.8125e-06\n"
     ]
    }
   ],
   "source": [
    "time_callback = TimeHistory()\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(SimpleRNN(64, input_shape=(32, 120), return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(SimpleRNN(32, return_sequences=False))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))    \n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(128, activation='linear', name = 'bottleneck'))\n",
    "\n",
    "model.add(Dense(100, activation='softmax'))  \n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-8)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,    \n",
    "    y_train,    \n",
    "    epochs=200,  \n",
    "    batch_size=32, \n",
    "    verbose = 1,\n",
    "    validation_data=(X_valid, y_valid),  \n",
    "    callbacks=[reduce_lr, early_stopping, time_callback]  \n",
    ")\n",
    "\n",
    "RNN_time = sum(time_callback.times[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "928787f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T17:01:58.414050Z",
     "iopub.status.busy": "2024-11-20T17:01:58.413182Z",
     "iopub.status.idle": "2024-11-20T17:01:58.489617Z",
     "shell.execute_reply": "2024-11-20T17:01:58.488663Z"
    },
    "papermill": {
     "duration": 12.707964,
     "end_time": "2024-11-20T17:01:58.491592",
     "exception": false,
     "start_time": "2024-11-20T17:01:45.783628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('model_RNN.h5')\n",
    "np.save('RNN_time.npy', RNN_time)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5923926,
     "sourceId": 9689961,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5924016,
     "sourceId": 9690086,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6114548,
     "sourceId": 9951161,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6114752,
     "sourceId": 9951425,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14696.135728,
   "end_time": "2024-11-20T17:02:13.841313",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-20T12:57:17.705585",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
